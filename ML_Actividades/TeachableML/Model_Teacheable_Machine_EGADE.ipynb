{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_dwkERJgUk-",
    "outputId": "3bc1b10d-914a-49c9-d960-b6abc5a998ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/converted_savedmodel.zip\n",
      "   creating: /content/model.savedmodel/\n",
      " extracting: /content/model.savedmodel/saved_model.pb  \n",
      "   creating: /content/model.savedmodel/assets/\n",
      "   creating: /content/model.savedmodel/variables/\n",
      " extracting: /content/model.savedmodel/variables/variables.index  \n",
      " extracting: /content/model.savedmodel/variables/variables.data-00000-of-00001  \n",
      " extracting: /content/labels.txt     \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/converted_savedmodel.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 1. Librerías\n",
    "# ================================\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "# ================================\n",
    "# 2. Cargar modelo SavedModel (local)\n",
    "# ================================\n",
    "# Carga el SavedModel exportado por el entrenamiento local en 'model_from_src'\n",
    "local_model_path = os.path.join(os.getcwd(), \"model_from_src\")\n",
    "fallback_model_path = \"/content/model\"  # por compatibilidad si usas Colab\n",
    "\n",
    "model_path = local_model_path if tf.io.gfile.exists(local_model_path) else fallback_model_path\n",
    "try:\n",
    "    model = tf.saved_model.load(model_path)\n",
    "    print(\"SavedModel cargado desde:\", model_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando SavedModel: {e}\")\n",
    "    model = None\n",
    "\n",
    "infer = None\n",
    "if model is not None:\n",
    "    try:\n",
    "        infer = model.signatures[\"serving_default\"]\n",
    "        print(\"Usando firma 'serving_default'.\")\n",
    "        print(\"Firma de entrada esperada:\")\n",
    "        for input_name, input_spec in infer.structured_input_signature[1].items():\n",
    "            print(f\"  Entrada '{input_name}': {input_spec}\")\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo obtener la firma:\", e)\n",
    "\n",
    "# ================================\n",
    "# 3. Leer imagen (de src/ si existe)\n",
    "# ================================\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"src\")\n",
    "img_path = None\n",
    "\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    # Busca una imagen cualquiera dentro de las subcarpetas de src/\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "    for root, _, files in os.walk(DATA_DIR):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(exts):\n",
    "                img_path = os.path.join(root, f)\n",
    "                break\n",
    "        if img_path:\n",
    "            break\n",
    "\n",
    "if img_path is None:\n",
    "    # Fallback a la ruta usada por el profesor en Colab\n",
    "    img_path = \"/content/manita.png\"\n",
    "\n",
    "print(\"Imagen a usar:\", img_path)\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Error: no se pudo cargar la imagen: {img_path}\")\n",
    "else:\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # ================================\n",
    "    # 4. Preparar la imagen para el modelo\n",
    "    # ================================\n",
    "    target_size = (224, 224)  # alto x ancho esperado por MobileNetV2\n",
    "    img_resized = cv2.resize(img_rgb, target_size)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_resized, 0), dtype=tf.float32)\n",
    "\n",
    "    # ================================\n",
    "    # 5. Inferencia\n",
    "    # ================================\n",
    "    if infer is not None:\n",
    "        print(\"\\nEjecutando inferencia...\")\n",
    "        try:\n",
    "            input_name = list(infer.structured_input_signature[1].keys())[0]\n",
    "            outputs = infer(**{input_name: input_tensor})\n",
    "            print(\"Claves de salida:\", list(outputs.keys()))\n",
    "\n",
    "            # ================================\n",
    "            # 6. Interpretación para clasificación (3 clases)\n",
    "            # ================================\n",
    "            # Toma el primer tensor de salida disponible y aplica softmax\n",
    "            first_key = list(outputs.keys())[0]\n",
    "            logits = outputs[first_key].numpy()\n",
    "            if logits.ndim == 2 and logits.shape[0] == 1:\n",
    "                probs = tf.nn.softmax(logits[0]).numpy()\n",
    "            else:\n",
    "                probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "\n",
    "            # Nombres de clases desde las subcarpetas de src/\n",
    "            class_names = None\n",
    "            if os.path.isdir(DATA_DIR):\n",
    "                class_names = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "\n",
    "            if class_names and len(class_names) == probs.shape[-1]:\n",
    "                for name, p in zip(class_names, probs):\n",
    "                    print(f\"{name}: {p*100:.2f}%\")\n",
    "                pred_idx = int(np.argmax(probs))\n",
    "                print(\"Predicción:\", class_names[pred_idx])\n",
    "            else:\n",
    "                print(\"Probabilidades:\", probs)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error durante la inferencia:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK7OXrcgh_3N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con 3 clases (hamburguesa, omelette, pizza)\n",
    "Este bloque usa las imágenes en `src/` y entrena un modelo con MobileNetV2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 141: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m VAL_SPLIT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     11\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1337\u001b[39m\n\u001b[1;32m---> 13\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVAL_SPLIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     23\u001b[0m     DATA_DIR,\n\u001b[0;32m     24\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39mVAL_SPLIT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m class_names \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mclass_names\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:232\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\dataset_utils.py:578\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    576\u001b[0m labels_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m--> 578\u001b[0m     partial_filenames, partial_labels \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     labels_list\u001b[38;5;241m.\u001b[39mappend(partial_labels)\n\u001b[0;32m    580\u001b[0m     filenames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m partial_filenames\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\dataset_utils.py:655\u001b[0m, in \u001b[0;36mindex_subdirectory\u001b[1;34m(directory, class_indices, follow_links, formats)\u001b[0m\n\u001b[0;32m    653\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    654\u001b[0m filenames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 655\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalid_files\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabsolute_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\dataset_utils.py:630\u001b[0m, in \u001b[0;36miter_valid_files\u001b[1;34m(directory, follow_links, formats)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     walk \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwalk(directory, followlinks\u001b[38;5;241m=\u001b[39mfollow_links)\n\u001b[1;32m--> 630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, _, files \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwalk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(files):\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(formats):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:876\u001b[0m, in \u001b[0;36mwalk_v2\u001b[1;34m(top, topdown, onerror)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m listing:\n\u001b[0;32m    875\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m _make_full_path(top, item)\n\u001b[1;32m--> 876\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    877\u001b[0m     subdirs\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m    878\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:689\u001b[0m, in \u001b[0;36mis_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgfile.IsDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_directory\u001b[39m(dirname):\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;124;03m    True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_directory_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:703\u001b[0m, in \u001b[0;36mis_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether the path is a directory or not.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m  True, if the path is a directory; False otherwise\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIsDirectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 141: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurar dataset desde carpeta local src/\n",
    "import os, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"src\")\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 1337\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\",\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\",\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Clases:\", class_names)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transfer learning: MobileNetV2 congelada + cabeza densa para 3 clases\n",
    "base = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,), include_top=False, weights=\"imagenet\"\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model_ft = keras.Model(inputs, outputs)\n",
    "\n",
    "model_ft.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "EPOCHS = 5\n",
    "history = model_ft.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar el modelo en formato SavedModel para reutilizarlo en la celda del profesor\n",
    "save_dir = os.path.join(os.getcwd(), \"model_from_src\")\n",
    "try:\n",
    "    tf.saved_model.save(model_ft, save_dir)\n",
    "    print(\"SavedModel exportado en:\", save_dir)\n",
    "except Exception as e:\n",
    "    print(\"Error al guardar SavedModel:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia con clases nuevas\n",
    "Usa la celda del profesor para cargar el SavedModel, y esta celda para mapear probabilidades a nombres de clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si ya tienes \"infer\" del SavedModel cargado, interpreta la salida como softmax y mapea a class_names.\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def predict_with_infer(img_path, target_size=(224,224)):\n",
    "    if \"infer\" not in globals() or infer is None:\n",
    "        print(\"Primero carga el modelo (firma 'serving_default').\")\n",
    "        return\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"No se pudo leer la imagen:\", img_path)\n",
    "        return\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, target_size)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_resized, 0), dtype=tf.float32)\n",
    "\n",
    "    input_name = list(infer.structured_input_signature[1].keys())[0]\n",
    "    outputs = infer(**{input_name: input_tensor})\n",
    "\n",
    "    # Intenta tomar el primer tensor de salida disponible\n",
    "    first_key = list(outputs.keys())[0]\n",
    "    logits = outputs[first_key].numpy()\n",
    "    if logits.ndim == 2 and logits.shape[0] == 1:\n",
    "        probs = tf.nn.softmax(logits[0]).numpy()\n",
    "    else:\n",
    "        probs = tf.nn.softmax(logits).numpy().squeeze()\n",
    "\n",
    "    if 'class_names' in globals():\n",
    "        for i,p in enumerate(probs):\n",
    "            print(f\"{class_names[i]}: {p*100:.2f}%\")\n",
    "        pred_idx = int(np.argmax(probs))\n",
    "        print(\"Predicción:\", class_names[pred_idx])\n",
    "    else:\n",
    "        print(\"Probabilidades:\", probs)\n",
    "\n",
    "# Ejemplo de uso (ajusta a una imagen de tu carpeta):\n",
    "# predict_with_infer(os.path.join(DATA_DIR, 'hamburguesa', 'cheeseburger.jpg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo local (alternativa a la celda del profesor)\n",
    "Carga el SavedModel exportado en `model_from_src` y expone la firma `infer`.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
