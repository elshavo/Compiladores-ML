{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MYb6GcE6c284"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# --- ¡NUEVO! --- \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Importamos las capas necesarias para la CNN y los Callbacks\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# --- ¡NUEVO! --- \n",
    "# Importamos las capas necesarias para la CNN y los Callbacks\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZYvFm8FgEX4"
   },
   "source": [
    "### Fashion-MNIST\n",
    "Fashion-MNIST es un conjunto de datos de imágenes de artículos de Zalando que consta de un conjunto de entrenamiento de 60 000 ejemplos y un conjunto de prueba de 10 000 ejemplos. Cada ejemplo es una imagen en escala de grises de 28x28, asociada con una etiqueta de 10 clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOrB7b1tc5hD"
   },
   "outputs": [],
   "source": [
    "#Descargar set de datos de Fashion MNIST de Zalando\n",
    "datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hbd3mw_YdmgL"
   },
   "outputs": [],
   "source": [
    "#Obtenemos en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
    "datos_entrenamiento, datos_pruebas = datos['train'], datos['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDfiICZ6duvD"
   },
   "outputs": [],
   "source": [
    "#Etiquetas de las 10 categorias posibles\n",
    "nombres_clases = metadatos.features['label'].names\n",
    "print(nombres_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_7qCeSBd9QK"
   },
   "outputs": [],
   "source": [
    "# --- CELDA MODIFICADA --- \n",
    "\n",
    "# Funcion de normalizacion (Pasar de 0-255 a 0-1)\n",
    "def normalizar(imagenes, etiquetas):\n",
    "  imagenes = tf.cast(imagenes, tf.float32)\n",
    "  imagenes /= 255 #reducción de [0-255] a [0,1]\n",
    "  return imagenes, etiquetas\n",
    "\n",
    "# Normalizar los datos de entrenamiento y pruebas con la funcion que hicimos\n",
    "datos_entrenamiento = datos_entrenamiento.map(normalizar)\n",
    "datos_pruebas = datos_pruebas.map(normalizar)\n",
    "\n",
    "# ¡NUEVO! Separar 10k datos de entrenamiento para validación\n",
    "num_ej_entrenamiento = metadatos.splits[\"train\"].num_examples\n",
    "num_ej_pruebas = metadatos.splits[\"test\"].num_examples\n",
    "print(f\"Ejemplos de entrenamiento originales: {num_ej_entrenamiento}\")\n",
    "print(f\"Ejemplos de prueba: {num_ej_pruebas}\")\n",
    "\n",
    "num_ej_validacion = 10000\n",
    "num_ej_entrenamiento_nuevo = num_ej_entrenamiento - num_ej_validacion\n",
    "print(f\"Ejemplos de entrenamiento nuevos: {num_ej_entrenamiento_nuevo}\")\n",
    "print(f\"Ejemplos de validación: {num_ej_validacion}\")\n",
    "\n",
    "datos_validacion = datos_entrenamiento.take(num_ej_validacion)\n",
    "datos_entrenamiento = datos_entrenamiento.skip(num_ej_validacion)\n",
    "\n",
    "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
    "datos_entrenamiento = datos_entrenamiento.cache()\n",
    "datos_validacion = datos_validacion.cache()\n",
    "datos_pruebas = datos_pruebas.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9_aRk7VeZSa"
   },
   "outputs": [],
   "source": [
    "#Mostrar una imagen de los datos de pruebas (ahora del set de 50k)\n",
    "for imagen, etiqueta in datos_entrenamiento.take(1):\n",
    "  break\n",
    "imagen = imagen.numpy().reshape((28,28)) #Redimensionar\n",
    "\n",
    "#Dibujar dibujar\n",
    "plt.figure()\n",
    "plt.imshow(imagen, cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8StEtDekef5a"
   },
   "outputs": [],
   "source": [
    "#Dibujar mas\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
    "  imagen = imagen.numpy().reshape((28,28))\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
    "  plt.xlabel(nombres_clases[etiqueta])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWnDC6fVjYGE"
   },
   "source": [
    "### Crear el modelo (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3l2QViuelfR"
   },
   "outputs": [],
   "source": [
    "# --- ¡NUEVA CELDA DE MODELO! ---\n",
    "# Esta es una Red Neuronal Convolucional (CNN)\n",
    "\n",
    "modelo = tf.keras.Sequential([\n",
    "    \n",
    "    # 1. Capa Convolucional: Busca 32 patrones (filtros) de 3x3.\n",
    "    # La entrada sigue siendo nuestra imagen de 28x28x1.\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    \n",
    "    # 2. Capa de Pooling: Reduce el tamaño de la imagen a la mitad (14x14).\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # 3. Segunda Capa Convolucional: Busca 64 patrones.\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # 4. Segunda Capa de Pooling: Reduce de nuevo (7x7).\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # 5. Aplanar (Flatten): Aplana las características aprendidas (7x7x64).\n",
    "    Flatten(),\n",
    "    \n",
    "    # 6. Capa Densa: 128 neuronas para clasificar los patrones.\n",
    "    Dense(128, activation=tf.nn.relu),\n",
    "    \n",
    "    # (Opcional) Dropout: Ayuda a prevenir el sobreajuste.\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # 7. Capa de Salida: 10 clases (sin cambios).\n",
    "    Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Imprime un resumen de tu nueva arquitectura\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30VnQNfvey_a"
   },
   "outputs": [],
   "source": [
    "# --- CELDA MODIFICADA --- \n",
    "# Preparamos los lotes para los 3 sets de datos\n",
    "\n",
    "TAMANO_LOTE = 32\n",
    "\n",
    "# Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria\n",
    "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento_nuevo).batch(TAMANO_LOTE)\n",
    "\n",
    "# Preparamos los lotes de validación y pruebas\n",
    "datos_validacion = datos_validacion.batch(TAMANO_LOTE)\n",
    "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ydAoEVjfKY"
   },
   "source": [
    "### Entrenamiento del modelo (Con Validación y EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpBMH_-He135"
   },
   "outputs": [],
   "source": [
    "# --- ¡NUEVA CELDA DE ENTRENAMIENTO! ---\n",
    "\n",
    "# Este callback monitorea la precisión de validación ('val_accuracy')\n",
    "# Si no mejora durante 3 épocas seguidas ('patience=3'), detiene el entrenamiento.\n",
    "# 'restore_best_weights=True' se asegura de que el modelo final sea el de la mejor época.\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "historial = modelo.fit(\n",
    "    datos_entrenamiento, \n",
    "    epochs=20, # Ponemos un número alto, EarlyStopping decidirá cuándo parar\n",
    "    steps_per_epoch= math.ceil(num_ej_entrenamiento_nuevo / TAMANO_LOTE),\n",
    "    validation_data=datos_validacion, # ¡Usamos el set de validación!\n",
    "    validation_steps=math.ceil(num_ej_validacion / TAMANO_LOTE),\n",
    "    callbacks=[early_stop] # ¡Añadimos el callback!\n",
    ")\n",
    "\n",
    "# Evalúa el modelo final con los datos de prueba para ver la precisión final\n",
    "print(\"\\n--- Evaluación Final con Datos de Prueba ---\")\n",
    "test_loss, test_accuracy = modelo.evaluate(datos_pruebas, steps=math.ceil(num_ej_pruebas/TAMANO_LOTE))\n",
    "print(f'\\nPrecisión final en pruebas: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Pcst1p2joJo"
   },
   "source": [
    "### Predicción\n",
    "Predicción utilizando nuestro modelo de red neuronal convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5Ko_R0ifGnB"
   },
   "outputs": [],
   "source": [
    "#Pintar una cuadricula con varias predicciones, y marcar si fue correcta (azul) o incorrecta (roja)\n",
    "\n",
    "for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):\n",
    "  imagenes_prueba = imagenes_prueba.numpy()\n",
    "  etiquetas_prueba = etiquetas_prueba.numpy()\n",
    "  predicciones = modelo.predict(imagenes_prueba)\n",
    "\n",
    "def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):\n",
    "  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
    "\n",
    "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
    "  if etiqueta_prediccion == etiqueta_real:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(nombres_clases[etiqueta_prediccion],\n",
    "                                100*np.max(arr_predicciones),\n",
    "                                nombres_clases[etiqueta_real]),\n",
    "                                color=color)\n",
    "\n",
    "def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):\n",
    "  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  grafica = plt.bar(range(10), arr_predicciones, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
    "\n",
    "  grafica[etiqueta_prediccion].set_color('red')\n",
    "  grafica[etiqueta_real].set_color('blue')\n",
    "\n",
    "filas = 5\n",
    "columnas = 5\n",
    "num_imagenes = filas*columnas\n",
    "plt.figure(figsize=(2*2*columnas, 2*filas))\n",
    "for i in range(num_imagenes):\n",
    "  plt.subplot(filas, 2*columnas, 2*i+1)\n",
    "  graficar_imagen(i, predicciones, etiquetas_prueba, imagenes_prueba)\n",
    "  plt.subplot(filas, 2*columnas, 2*i+2)\n",
    "  graficar_valor_arreglo(i, predicciones, etiquetas_prueba)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
